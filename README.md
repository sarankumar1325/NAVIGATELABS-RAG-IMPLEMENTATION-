# Simple Local RAG Tutorial

## Overview

This tutorial guides you through building a local Retrieval-Augmented Generation (RAG) pipeline that runs entirely on your own hardware with an NVIDIA GPU.

![Local RAG Workflow Diagram](images/simple-local-rag-workflow-flowchart.png)

The workflow processes documents (such as PDFs), chunks them into manageable segments, embeds these chunks using transformer models, and enables natural language querying with responses generated by a locally-run Large Language Model (LLM).

In this tutorial, we'll build NutriChat, a specialized RAG application that allows users to query a 1200-page Nutrition Textbook and receive responses based on the textbook's content.

**Source Material:** [Human Nutrition Open Educational Resource](https://pressbooks.oer.hawaii.edu/humannutrition2/)

**Alternative Environment:** You can also run the included notebook `00-simple-local-rag.ipynb` directly in [Google Colab](https://colab.research.google.com/github/mrdbourke/simple-local-rag/blob/main/00-simple-local-rag.ipynb).

## Getting Started

You have two options for running this tutorial:

1. **Local Execution:** If you have a local NVIDIA GPU with 5GB+ VRAM, follow the setup instructions below to run the pipeline locally.
2. **Cloud Execution:** If you don't have a suitable local GPU, you can follow along using Google Colab with their provided NVIDIA GPU resources.

## Prerequisites

- Python programming knowledge
- Basic understanding of machine learning and deep learning concepts
- Familiarity with PyTorch (optional but helpful) - see this [beginner PyTorch video](https://youtu.be/Z_ikDlimN6A?si=NIkrslkvHaNdlYgx) for an introduction

## Setup Instructions

This tutorial has been tested with Python 3.11 on Windows 11 using an NVIDIA RTX 4090 with CUDA 12.1.

### 1. Clone Repository
